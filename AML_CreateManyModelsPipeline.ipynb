{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc8096-4694-4a79-801c-f00e7db341b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82510f-2074-46b6-9721-360df9213494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AML Workspace\n",
    "ws = None\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "except Exception:\n",
    "    ws = Workspace(subscription_id=os.getenv('SUBSCRIPTION_ID'),  resource_group = os.getenv('RESOURCE_GROUP'), workspace_name = os.getenv('WORKSPACE_NAME'))\n",
    "\n",
    "\n",
    "#Select AML Compute Cluster\n",
    "cpu_cluster_name = 'cluster001'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found an existing cluster, using it instead.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=3)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    cpu_cluster.wait_for_completion(show_output=True)\n",
    "    \n",
    "#Get default datastore\n",
    "default_ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e4bc5-66e6-42af-a2d6-26c149aa9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_env = Environment.from_pip_requirements(name='ManyModelsEnv', file_path='./requirements.txt')\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.docker.use_docker = True\n",
    "run_config.environment = aml_env\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "run_config.docker.arguments = ['-v', '/var/run/docker.sock:/var/run/docker.sock']\n",
    "run_config.environment.python.conda_dependencies.set_python_version('3.8.10')\n",
    "\n",
    "#Register environment for reuse \n",
    "run_config.environment.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51f763-fb5d-4c4b-a464-ef3a487dda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = OutputFileDatasetConfig(name='HomePrices_Raw_Data', destination=(default_ds, 'homeprices_raw_data/{run-id}')).read_delimited_files().register_on_complete(name='HomePrices_Raw_Data')\n",
    "training_data = OutputFileDatasetConfig(name='HomePrices_Training_Data', destination=(default_ds, 'homeprices_training_data/{run-id}')).register_on_complete(name='HomePrices_Training_Data')\n",
    "testing_data = OutputFileDatasetConfig(name='HomePrices_Testing_Data', destination=(default_ds, 'homeprices_testing_data/{run-id}')).register_on_complete(name='HomePrices_Testing_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ddadb-bc49-4387-8290-9826a98bfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "output_dir = PipelineData(name=\"training_output\", datastore=default_ds)\n",
    "test_output_dir = PipelineData(name=\"testing_output\", datastore=default_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbcd43-bcc4-4b58-9ae8-8d4f2b95c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_size = PipelineParameter(name='testing_size', default_value=0.3)\n",
    "target_column = PipelineParameter(name='target_column', default_value='target')\n",
    "deployment_name = PipelineParameter(name='deployment_name', default_value='manymodelsdeployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680c941-bac2-4de0-a2db-d616569f07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw data from AML-linked datastore\n",
    "# Register tabular dataset after retrieval\n",
    "get_data_step = PythonScriptStep(\n",
    "    name='Get Data',\n",
    "    script_name='get_data.py',\n",
    "    arguments =['--raw_data', raw_data],\n",
    "    outputs=[raw_data],\n",
    "    compute_target=cpu_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "# Load raw data and split into test and train\n",
    "# datasets according to the specified split percentage\n",
    "split_data_step = PythonScriptStep(\n",
    "    name='Split Train and Test Data',\n",
    "    script_name='split_data.py',\n",
    "    arguments =['--training_data', training_data,\n",
    "                '--testing_data', testing_data,\n",
    "                '--testing_size', testing_size],\n",
    "    inputs=[raw_data.as_input(name='Raw_Data')],\n",
    "    outputs=[training_data, testing_data],\n",
    "    compute_target=cpu_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "from azureml.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "# Define the ParallelRunConfig object\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    entry_script='train_models.py', # the user script that will be run in parallel\n",
    "    mini_batch_size=\"1\",\n",
    "    error_threshold=-1,\n",
    "    output_action=\"append_row\",\n",
    "    environment=aml_env,\n",
    "    compute_target=cpu_cluster,\n",
    "    node_count=1\n",
    ")\n",
    "\n",
    "train_models_step = ParallelRunStep(\n",
    "    name='Train Models',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[training_data.as_input(name='train_data')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    entry_script='evaluate_models.py', # the user script that will be run in parallel\n",
    "    mini_batch_size=\"1\",\n",
    "    error_threshold=-1,\n",
    "    output_action=\"append_row\",\n",
    "    environment=aml_env,\n",
    "    compute_target=cpu_cluster,\n",
    "    node_count=1\n",
    ")\n",
    "\n",
    "evaluate_models_step = ParallelRunStep(\n",
    "    name='Evaluate Models',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[testing_data.as_input(name='test_data')],\n",
    "    output=test_output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=False\n",
    ")\n",
    "\n",
    "evaluate_models_step.run_after(train_models_step)\n",
    "\n",
    "create_deployment_step = PythonScriptStep(\n",
    "    name='Package Models',\n",
    "    script_name='package_models.py',\n",
    "    arguments =['--deployment_name', deployment_name],\n",
    "    inputs=[training_data.as_input(name='train_data').as_download('./training-data')],\n",
    "    compute_target=cpu_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "create_deployment_step.run_after(evaluate_models_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fba26c-104a-40b8-b2c1-825785b4c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[get_data_step, split_data_step, train_models_step, evaluate_models_step, create_deployment_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04be510-4e85-4f97-9dd4-5049537cc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = os.getenv('EXPERIMENT_NAME', 'many-models-pipeline-run')\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
